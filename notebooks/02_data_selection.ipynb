{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0a12cf",
   "metadata": {},
   "source": [
    "# 2. Data Selection\n",
    "\n",
    "> “The quality of a composite indicator is directly linked to the quality of the variables selected.” - Gotten from the OECD Handbook on Composite Indicators\n",
    "\n",
    "In this notebook, I will select the data that will be used to calculate the CSIAI and also justifications where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922dcc0a",
   "metadata": {},
   "source": [
    "## 2.1. Statistical Quality Principles\n",
    "\n",
    "There are principles that an indicator must satisfy **all seven** or be rejected:\n",
    "\n",
    "1. **Relevance** — captures something the theoretical framework says matters.  \n",
    "2. **Accuracy** — sourced from audited statements and raw market data.  \n",
    "3. **Timeliness** — updates at least quarterly; daily preferred in my case as discussed with **Dr. John Loane** and it is also the frequency of the CSIAI.  \n",
    "4. **Accessibility** — free via `yfinance`.  \n",
    "5. **Interpretability** — unit and direction are intuitive.  \n",
    "6. **Comparability** — works across all sectors.  \n",
    "7. **Coherence** — definitions do not conflict with other metrics.\n",
    "\n",
    "If any of the indicators fail to meet these principles then I will exclude them or I can use a proxy with proper justification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23badbf",
   "metadata": {},
   "source": [
    "## 2.2. Defining the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f280ecb",
   "metadata": {},
   "source": [
    "### 2.2.1. Why Russell 3000?\n",
    "\n",
    "* it covers 98 % of U.S. market capitalisation and is the most widely used benchmark for U.S. equities.\n",
    "* It is a broad index that includes large, mid, and small-cap stocks.\n",
    "* The list is public and can be found on [Wikipedia](https://en.wikipedia.org/wiki/Russell_3000_Index).\n",
    "* The index is reconstituted annually, which means that it is updated regularly to reflect changes in the market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc05bad6",
   "metadata": {},
   "source": [
    "### 2.2.2. Why require 24 months of price history (start 2023-01-01)?\n",
    "\n",
    "The Risk metrics (beta, Sharpe ratio, maximum draw-down) need at least one full market cycle and in the Handbook in Section 3 it recommends “adequate observational base”.  Two years provides:\n",
    "* ≈ 500 trading days: This is a reliable number of trading days to estimate volatility.\n",
    "* IPOs - Initial Public Offerings - younger than 6 months are excluded to avoid data sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ff3c0",
   "metadata": {},
   "source": [
    "### 2.2.3. Why filter on **average 30-day volume ≥ 50 000 shares**?\n",
    "\n",
    "* Ensures **Liquidity & Trading** sub-index is not dominated by stocks that are thinly traded.\n",
    "* 50,000 shares/day is a common threshold for liquidity in the finance literature taking for example in this case the work of **Gao & Ongena (2021)** and this threshold keeps ≈ 80 % of the Russell 3000 index.\n",
    "* This threshold also reduces the estimation error in bid-ask spread calculations, which is about how the market is functioning and how much it costs to trade a stock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccc785",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.2.4  Reliable ticker source\n",
    "\n",
    "The iShares Russell 3000 ETF (ticker **IWV**) publishes its full holdings every night as a CSV file.\n",
    "\n",
    "Advantages:\n",
    "* **Authoritative** — the fund must hold every Russell 3000 constituent.  \n",
    "* **Timely** — file refreshes after each U.S. trading day.  \n",
    "* **Stable URL** — the `.ajax` endpoint is version agnostic  which means it will not change.\n",
    "* **Free** — no login or API key required.\n",
    "* **Clean “Holdings” sheet** — tickers are listed in a single column.\n",
    "\n",
    "We skip the first **seven** metadata rows, treat row 8 as the header, select the **“Ticker”** column, and drop empties, dashes, or placeholders - All these will be done dynamically in the code.\n",
    "\n",
    "* **Local CSV fallback**  \n",
    "If the network call fails or you simply prefer, drop the current file you downloaded manually at `data/input/IWV_holdings.csv`. The loader will auto-detect it and skip the web request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650e287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local IWV CSV: ../data/input/IWV_holdings.csv\n",
      "Fetched 2656 tickers from IWV holdings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21 Failed downloads:\n",
      "['P5N994', 'UHALB', 'ESM5', 'LGFA', 'BFA', 'GTXI', 'LENB', 'METCV', 'CWENA', 'GEFB', 'BFB', 'MSFUT', 'LGFB', 'MOGA', 'HEIA', 'RTYM5', 'BRKB', 'ADRO', 'XTSLA']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "['INH', 'CLSKW']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-03-27 -> 2025-05-06)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universe size after liquidity filter: 2563\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, requests, io, os, datetime as dt, yfinance as yf\n",
    "from tqdm import tqdm\n",
    "import warnings, pathlib\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Define the base data directory\n",
    "DATA_DIR = pathlib.Path(\"..\") / \"data\"\n",
    "\n",
    "# Ensure the data directory exists\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUT_DIR = DATA_DIR / \"input\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "# Ensure folders exist\n",
    "INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOCAL_FILE = INPUT_DIR / \"IWV_holdings.csv\"\n",
    "\n",
    "REMOTE_URL = (\"https://www.ishares.com/us/products/239714/ishares-russell-3000-etf/1467271812596.ajax?fileType=csv&fileName=IWV_holdings&dataType=fund\")\n",
    "\n",
    "def load_iwv_csv() -> bytes:\n",
    "    \"Return CSV bytes local first, else remote download and cache.\"\n",
    "    if LOCAL_FILE.exists() and LOCAL_FILE.stat().st_size > 0:\n",
    "        print(\"Using local IWV CSV:\", LOCAL_FILE)\n",
    "        return LOCAL_FILE.read_bytes()\n",
    "    print(\"Downloading IWV holdings CSV …\")\n",
    "    r = requests.get(REMOTE_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    LOCAL_FILE.write_bytes(r.content)\n",
    "    print(\"Saved snapshot to:\", LOCAL_FILE)\n",
    "    return r.content\n",
    "\n",
    "def extract_tickers(csv_bytes: bytes) -> list[str]:\n",
    "    \"\"\"\n",
    "    Parses the CSV content to extract ticker symbols.\n",
    "    Handles metadata at the beginning and footnotes at the end.\n",
    "    \"\"\"\n",
    "    # Decode the bytes to a string\n",
    "    csv_text = csv_bytes.decode('utf-8', errors='ignore')\n",
    "    lines = csv_text.splitlines()\n",
    "\n",
    "    # Identify the header row\n",
    "    header_line_index = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if 'Ticker' in line:\n",
    "            header_line_index = i\n",
    "            break\n",
    "\n",
    "    if header_line_index is None:\n",
    "        raise ValueError(\"Ticker header not found in the CSV file.\")\n",
    "\n",
    "    # Read the data starting from the header\n",
    "    data_lines = lines[header_line_index:]\n",
    "\n",
    "    # Stop reading when an empty line is encountered\n",
    "    for j, line in enumerate(data_lines):\n",
    "        if not line.strip():\n",
    "            data_lines = data_lines[:j]\n",
    "            break\n",
    "\n",
    "    # Create a DataFrame from the data lines\n",
    "    data_str = '\\n'.join(data_lines)\n",
    "    df = pd.read_csv(io.StringIO(data_str))\n",
    "\n",
    "    # Clean and extract ticker symbols\n",
    "    tickers = (df['Ticker'].astype(str).str.strip().replace({'': pd.NA, '-': pd.NA}).dropna().str.replace(r'\\.', '-', regex=True).unique().tolist())\n",
    "\n",
    "    return tickers\n",
    "\n",
    "# to run the loader\n",
    "csv_bytes = load_iwv_csv()\n",
    "tickers = extract_tickers(csv_bytes)\n",
    "print(f\"Fetched {len(tickers)} tickers from IWV holdings\")\n",
    "\n",
    "# The parameters to filter the tickers in the yfinance\n",
    "START, END = \"2023-01-01\", dt.date.today().isoformat()\n",
    "# shares/day\n",
    "VOL_THRESHOLD = 50_000\n",
    "\n",
    "# Liquidity filter using a 40 day window\n",
    "prices = yf.download(\" \".join(tickers), start=dt.date.fromisoformat(END) - dt.timedelta(days=40), end=END, group_by=\"ticker\", threads=True, progress=False)\n",
    "\n",
    "liquid = []\n",
    "for t in tickers:\n",
    "    try:\n",
    "        if prices[t][\"Volume\"].tail(30).mean() >= VOL_THRESHOLD:\n",
    "            liquid.append(t)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "print(f\"Universe size after liquidity filter: {len(liquid)}\")\n",
    "universe = pd.DataFrame({\"ticker\": liquid})\n",
    "universe.to_parquet(PROCESSED_DIR / \"universe.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
